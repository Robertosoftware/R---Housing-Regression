---
title: "Entrega III Individual"
description: |
  Entrega SEMMA: KNN + CART + RANDOM FOREST
author:
  - name: Roberto Bonilla Ibarra
    url: 
    affiliation: Universidad Complutense de Madrid
    affiliation_url: 
date: "`r Sys.Date()`"
output:
    distill::distill_article:
        highlight: kate
        colorlinks: true
        code_folding: false
        toc: true            
        toc_depth: 3     
---

```{r setup, include = FALSE}
# Ajuste comunes de los chunk
knitr::opts_chunk$set(fig.width = 8, fig.asp = 1, out.width = "100%",
                      message = FALSE, warning = FALSE,
                      echo = TRUE, res = 400)
```

# Objetivo {#objetivo}

El objetivo de esta entrega es poder predecir si los individuos recibir치n un sueldo mayor o menor o igual a 50 mil d칩lares mensuales basado en sus caracter칤sticas socioecon칩micas, usando tres diferentes algoritmos de clasificaci칩n (knn, 치rboles y random forest).

## Paquetes necesarios

Necesitaremos los siguientes paquetes

* **An치lisis exploratorio num칠rico**: paquete `{skimr}`
* **Depuraci칩n y preprocesamiento**: paquete `{tidyverse}`
* **Modelizaci칩n**: paquete `{tidymodels}` para modelos
* **Detecci칩n de outliers**: paquete `{outliers}`


```{r paquetes}
# Borramos
rm(list = ls())

# Paquetes
library(skimr) # resumen num칠rico
library(tidymodels) # depuraci칩n datos
library(tidyverse) # modelos
library(outliers) # outliers
library(timeDate) # fechas
library(ggthemes) # tema para graficar
library(ranger) # Random Forest 
library(corrr) # Crear correlaciones
library(corrplot) # Crear matriz de correlaci칩n
library(parallel) # Librer칤as de C칩mputo en Paralelo
library(doParallel) # Librer칤as de C칩mputo en Paralelo
library("rpart.plot") # Librer칤a para visualizar la l칩gica dentro del algoritmo de 치rboles.
library(vip) # Librer칤a para visualizar la importancia de las variables dentro del algoritmo de 치rboles.
```

# Datos {#datos}

Vamos ir a un **ejemplo real**, haciendo uso de un **dataset de adultos con distintas variables socioecon칩micas.**

```{r}
adultos <- read_csv(file = "./datos/adults.csv")
```

Los datos forman parte de un **censo poblacional relacionado a la percepci칩n econ칩mica** elaborado por US Census Bureau con 32,561 registros.

游닄 **Detalle de variables**: <http://www.cs.toronto.edu/~delve/data/adult/adultDetail.html1>



## An치lisis exploratorio inicial (num칠rico)

Antes de tomar ninguna decisi칩n con los datos lo primero que deber칤amos hacer es **echar un vistazo num칠rico** a c칩mo se comportan las variables. Dado que vamos a clasificar, lo primero que deber칤amos observar es como se distribuyen los niveles de nuestra variable objetivo.

### Variables

Lo primero es conocer las variables

```{r}
glimpse(adultos)
```

* `age`: Edad de los individuos
* `workclass`: Tipo de trabajo de cada individuo
* `fnlwgt`: N칰mero de personas con la misma edad y raza.
* `education,education_num`: Nivel de educaci칩n m치ximo
* `marital_status`: Situaci칩n sentimental del individuo.
* `occupation`: A lo que se dedica el individuo
* `relationship`: Cu치l es la relaci칩n que tiene con su familia.
* `race`: Raza del individuo
* `sex`: Sexo del individuo
* `capital_gain`: Capital percibido
* `capital_loss`: Capital perdido
* `hours_per_week`: Horas de trabajo semanales
* `native_country`: Pa칤s de origen
* `over_50k`: Si el individuo percibe un ingreso mayor a 50 mil d칩lares anuales o menor o igual a este.


Adem치s con la funci칩n `skim()` del paquete `{skimr}` podemos **extraer algunas estad칤sticas b치sicas** de nuestros datos.

```{r skim}
# Resumen num칠rico
adultos |> skim()
```

Veamos los tipos de dato de las variables:

```{r}
sapply(adultos, class)
```

Podemos ver que tenemos que cambiar el tipo de dato de la variable capital loss y capital gain, veamos su distribuci칩n,

**Capital Gain**
```{r}
adultos |> 
  count(capital_gain) |>
  mutate(porc = 100*n/sum(n))

```

**Capital Loss**

```{r}
adultos |> 
  count(capital_loss) |>
  mutate(porc = 100*n/sum(n))
```

Hemos visto que son variables continuas, por la tanto las convertiremos en num칠ricas:

```{r}
adultos$capital_gain <- as.numeric(str_replace_all(adultos$capital_gain,',',''))
adultos$capital_loss <- as.numeric(str_replace_all(adultos$capital_loss,',',''))
```


### Balance la variable objetivo

El objetivo ser치 **predecir si un adulto est치 destinado a recibir un ingreso mayor a 50 mil d칩lares anuales o menor o igual a este**, por lo que la variable `over_50k` ser치 nuestra variable objetivo. Primer paso: conocer c칩mo se **distribuyen los niveles de la objetivo** (es binaria)


```{r}
adultos |> 
  count(over_50k) |>
  mutate(porc = 100*n/sum(n))
```

Podemos ver que nuestra variable objetivo est치 desbalanceada hacia las personas con un ingreso menor o igual a 50 mil d칩lares.


# An치lisis Exploratorio Visual

Antes de poder tomar decisiones en c칩mo transformar nuestros datos es importante poder hacer un an치lisis detallado visual de nuestros datos y conocer c칩mo interact칰an con la variable objetivo:

Para esto usaremos el tema del economist del paquete ggplothemes

## Distribuci칩n visual variable objetivo

La Variable Objetivo se encuentre desbalanceda, teniendo un 75% de casos donde las personas ganan menos que 50 mil d칩lares al a침o.

```{r}
ggplot(adultos, aes(x = over_50k, fill = over_50k)) +
  geom_bar(color = "white", alpha = 0.3) +
  scale_fill_brewer(palette = "Dark2") +
  labs(title = "Variable objetivo",
       subtitle = "Distribuci칩n de ingresos",
       x = "Cantidad", y = "Frecuencia") +
  theme_economist()

```


## Distribuci칩n visual variables continuas

### Variable Edad

```{r}
ggplot(adultos, aes(x = age, fill = over_50k)) +
    geom_density(alpha = .3) +
    labs(title = "Variable Edad",
       subtitle = "Distribuci칩n de Edad con diferencia de Variable Objetivo",
       x = "Edad", y = "Frecuencia") +
  theme_economist()
```

Podemos ver que las personas que ganan m치s de 50 mil d칩lares al a침o tienden a ser de mayor edad en comparaci칩n con los que hacen menos o igual a 50 mil d칩lares al a침o, tambi칠n podemos ver que la mayor칤a est치n entre 30 y 55 a침os.

```{r}
ggplot(adultos, aes(x = over_50k, y = age, color=over_50k)) +
  geom_boxplot() +
  stat_summary(fun.y = "mean", geom = "point", shape = 23, size = 3, fill = "white") +
   labs(title = "Variable Edad",
       subtitle = "Distribuci칩n de Edad por Tipo de Ingreso",
       x = "Over 50k", y = "Cantidad") +
  theme_economist()
```

### Variable Capital Gain

Ahora veamos como se comporta la variable de Capital Ganado

```{r}
ggplot(adultos, aes(x = capital_gain, fill = over_50k)) +
    geom_density(alpha = .6) + # Grado de transparencia para ver la gr치fica traspuesta
  scale_y_continuous(limits = c(0, .0001)) + # Para poder visualizar mejor la gr치fica
    labs(title = "Variable Capital Ganado",
       subtitle = "Distribuci칩n de Capital Ganado con diferencia de Variable Objetivo",
       x = "Capital Ganado", y = "Frecuencia") +
  theme_economist()
```


Podemos ver que las personas que perciben un ingreso mayor a 50K USD tienden a tener capital ganado en comparaci칩n con los que no perciben un ingreso mayor a 50k USD.

```{r}
ggplot(adultos |>  filter(capital_gain<20000), aes(x = capital_gain, fill = over_50k)) +
    geom_histogram(position = "identity", alpha = 0.4, bins=20) + # Posici칩n identity para que se puedan trasponer los histogramas
     labs(title = "Variable Capital Ganado",
       subtitle = "Distribuci칩n de Capital Ganado con diferencia de Variable Objetivo",
       x = "Capital Gain", y = "Frecuencia") +
  theme_economist()
```


Podemos corroborar lo que mencionamos arriba, donde si bien la mayor칤a de las personas no ganan capital, cuando ellas documentan que perciben cierto capital tienen m치s probabilidad de ser del grupo de personas que perciben un ingreso mayor a 50 K USD.

```{r}
ggplot(adultos, aes(x = capital_gain, y = education, color=over_50k)) +
  geom_point() +
   labs(title = "Variable Capital Ganado",
       subtitle = "Distribuci칩n de Capital Ganado por Educaci칩n") +
  theme_economist()
```

Podemos ver que las personas que tienen un nivel acad칠mico bajo tienden a reportar un capital ganado bajo o nulo y a la vez este repercute en el ingreso anual que perciben en el a침o.

### Variable Capital Loss

Ahora analizaremos la variable de Capital Perdido

```{r}
ggplot(adultos, aes(x = over_50k, y = capital_loss, color=over_50k)) +
  geom_boxplot() +
  stat_summary(fun.y = "mean", geom = "point", shape = 23, size = 3, fill = "white") +
   labs(title = "Variable Capital Perdido",
       subtitle = "Distribuci칩n del Capital Perdido",
       x = "Over 50k", y = "Cantidad") +
  theme_economist()
```

Podemos ver que los percentiles 25, 50 y 75 se encuentran en 0, se침alando que la mayor parte de las personas no tienen capital perdido, sin embargo al ver la distribuci칩n podemos determinar que en el caso que una persona tenga perdida de capital, es muy probable que si ella percibe un ingreso menor a 50 mil USD sea baja y visceversa, determinando esto tambi칠n por donde se posiciona la media de cada grupo. (Las personas conun ingreso m치s alto son menos en los casos de perdida, sin embargo, su media es m치s alta) 

```{r}

ggplot(adultos, aes(x = capital_loss, fill = over_50k)) +
    geom_density(alpha = .6) +
  scale_y_continuous(limits = c(0, .002)) +
    labs(title = "Variable Capital Perdido",
       subtitle = "Distribuci칩n de Capital Perdidoe con diferencia por Tipo de Ingreso",
       x = "Capital Perdido", y = "Frecuencia") +
  theme_economist()
```

Esta gr치fica confirma la observaci칩n marcada anteriormente con respecto al capital perdido, lo importante a resaltas es que al ser est치 gr치fica la densidad de la distribuci칩n se aprecia de mejor manera.

### Variable Hours_per_week

```{r}

ggplot(adultos, aes(x =  hours_per_week, fill = over_50k)) +
    geom_density(position = "identity", alpha = 0.4, bins=20) +
    labs(title = "Variable Horas a la Semana",
       subtitle = "Distribuci칩n de Horas a la Semana con diferencia de Variable Objetivo",
       x = "Horas a la Semana", y = "Frecuencia") +
  theme_economist()
```

Podemos ver que las personas con un ingreso 

### Variable fnlwgt


```{r}

ggplot(adultos, aes(x = fnlwgt, fill = over_50k)) +
    geom_density(alpha = .3) +
    labs(title = "Variable fnlwgt",
       subtitle = "Distribuci칩n de Fnlwgt con diferencia de Variable Objetivo",
       x = "Fnlwgt", y = "Frecuencia") +
  theme_economist()
```

Podemos ver que no existe ning칰n patr칩n entre las dos distribuciones.

## Distribuci칩n visual variables continuas

### Variable Clase de Trabajo

Analizaremos la variable **Clase de Trabajo** y su relaci칩n con la variable objetivo:

```{r}
  ggplot(adultos, aes(y = workclass, fill=over_50k)) +
  geom_bar(color = "white", alpha = 0.3) +
  labs(title = "Variable Clases de Trabajo",
       subtitle = "Distribuci칩n de Clases de Trabajo",
       x = "Personas", y = "Clases de Trabajo") +
  geom_text(size = 2.5,stat='count', aes(label=after_stat(count)), position=position_stack(vjust=0.5)) + 
  theme_economist()
```

### Variable Estado Civil

Analizaremos la variable **Estado Civil** y su relaci칩n con la variable objetivo:

```{r}
  ggplot(adultos, aes(y = marital_status, fill=over_50k)) +
  geom_bar(color = "white", alpha = 0.3) +
  labs(title = "Variable Estado Civil",
       subtitle = "Distribuci칩n del Estado Civil",
       x = "Personas", y = "Estado Civil") +
  geom_text(size = 2.5,stat='count', aes(label=after_stat(count)), position=position_stack(vjust=0.5)) + 
  theme_economist()
```

Podemos ver un comportamiento muy importante en la clase donde la gente se ha casado de manera civil, teniendo una gran cantidad y proporci칩n mucho m치s favorable para los individuos que ganan m치s de 50 mil USD al a침o.

### Variable Ocupaci칩n

Analizaremos la variable *Ocupaci칩n** y su relaci칩n con la variable objetivo:

```{r}
  ggplot(adultos, aes(y = occupation, fill=over_50k)) +
  geom_bar(color = "white", alpha = 0.3) +
  labs(title = "Variable Ocupaci칩n",
       subtitle = "Distribuci칩n de la variable Ocupaci칩n",
       x = "Personas", y = "Ocupaci칩n") +
  geom_text(size = 2.5,stat='count', aes(label=after_stat(count)), position=position_stack(vjust=0.5)) + 
  theme_economist()
```

Como era de esperarse las clases que hacen una diferencia en su distribuci칩n son **Prof-Speciality** y **Exec-Managerial** por el tipo de ingreso que llevan estos dos grupos de personas.

### Variable Relaci칩n

Analizaremos la variable *Relaci칩n** y su relaci칩n con la variable objetivo:

```{r}
  ggplot(adultos, aes(y = relationship, fill=over_50k)) +
  geom_bar(color = "white", alpha = 0.3) +
  labs(title = "Variable Relaci칩n",
       subtitle = "Distribuci칩n de la variable Relaci칩n",
       x = "Personas", y = "Relaci칩n") +
  geom_text(size = 2.5,stat='count', aes(label=after_stat(count)), position=position_stack(vjust=0.5)) + 
  theme_economist()
```

Vemos aqu칤 que los jedes de familia son en su mayor칤a los que perciben un ingreso mayor a 50 mil d칩lares anuales.

### Variable Raza

Analizaremos la variable *Raza** y su relaci칩n con la variable objetivo:

```{r}
  ggplot(adultos, aes(y = race, fill=over_50k)) +
  geom_bar(color = "white", alpha = 0.3) +
  labs(title = "Variable Raza",
       subtitle = "Distribuci칩n de la variable Raza",
       x = "Personas", y = "Raza") +
  geom_text(size = 2.5,stat='count', aes(label=after_stat(count)), position=position_stack(vjust=0.5)) + 
  theme_economist()
```

Podemos ver que los asi치ticos y blancos son los m치s propensos a percibir un ingreso superior a 50 mil d칩lares anuales.

### Variable Sexo

Analizaremos la variable *Sexo** y su relaci칩n con la variable objetivo:

```{r}
  ggplot(adultos, aes(y = sex, fill=over_50k)) +
  geom_bar(color = "white", alpha = 0.3) +
  labs(title = "Variable Sexo",
       subtitle = "Distribuci칩n de la variable Sexo",
       x = "Personas", y = "Sexo") +
  geom_text(size = 2.5,stat='count', aes(label=after_stat(count)), position=position_stack(vjust=0.5)) + 
  theme_economist()
```

Podemos ver que al agruparse la poblaci칩n, el sexo masculino tiene una mayor posibilidad de percibir un ingreso superior a 50 mil d칩lares anuales.


### Variable Pa칤s

Analizaremos la variable *Pa칤s** y su relaci칩n con la variable objetivo:

```{r}
  ggplot(adultos, aes(y = native_country, fill=over_50k)) +
  geom_bar(color = "white", alpha = 0.3) +
  labs(title = "Variable Pa칤s",
       subtitle = "Distribuci칩n de la variable Pa칤s en %",
       x = "Personas", y = "Pa칤s") +
  geom_text(size = 2.5,stat='count', aes(label=after_stat(round(count / sum(count),2) * 100)), position=position_stack(vjust=0.5)) + 
  theme_economist()
```

Podemos ver que alrededor del 90% de las personas han nacido en Estados Unidos.

### Variable 

# Introducci칩n Te칩rica

Explicaremos brevemente cada uno de los algoritmos que se usar치n en esta pr치ctica:


## KNN

Es uno de los modelos de Machine Learning m치s sencillos. 

Su l칩gica es asumir la similaridad entre un nuevo caso o dato y los otros puntos disponibles, colocando este nuevo punto en las categor칤as previamente definidas.

Algoritmo usado para regresi칩n y clasificaci칩n.

Es un algoritmo de aprendizaje vago (lazy learner algorithm) ya que hace un almacenamiento de los datos de entrenamiento y espera hasta que reciba los datos de testing para poder empezar a clasificar, haciendo que tome menos tiempo en entrenamiento, pero m치s tiempo prediciendo.


El funcionamiento del algoritmo de KNN es el siguiente:

**Paso 1**: Seleccionamos el n칰mero K de vecinos.

**Paso 2**: Calculamos la distancia euclidea de los k vecinos.

**Paso 3**: Tomamos el K vecino m치s cercano

**Paso 4**: Entre los K vecinos contamos el n칰mero de datos que se encuentran en cada categor칤a 

**Paso 5**: Asignamos a la categor칤a que cuente con el mayor n칰mero de vecinos.

**Paso 6**: Contamos con el modelo listo

```{r echo = FALSE, results = 'asis'}
image = "https://datascientest.com/es/wp-content/uploads/sites/7/2020/11/Illu-2-KNN-1024x492.jpg"
cat(paste0('<center><img src="', image,  '"></center>')) 
```

Fuente: <https://www.javatpoint.com/k-nearest-neighbor-algorithm-for-machine-learning>

## 츼rboles de Decisi칩n

Los arboles de decisi칩n es un modelo de aprendizaje supervisado que sive para resolver problemas de clasificaci칩n y regresi칩n, tambi칠n conocido como `Classification And Regression Tree (CART) algorithm.`

Con base a la variable objetivo podemos definir los 치rboles de decisi칩n en dos tipos:

1. 츼rboles de Decisi칩n de Variables Categ칩ricas
2. 츼rboles de Decisi칩n de Variables Continuas

Un 치rbol de decisi칩n es un clasificador en forma de 치rbol donde nodos internos representan variables del dataset, generando ramas que son reglas de decisi칩n y cada hoja representa el resultado.

La fortaleza de un 치rbol de decisi칩n es que son sumamente interpretables y representan la forma de pensar humana.

Para construir el modelo se puede sintetizar en los siguientes pasos:

**Paso 1**: Comenzar el 치rbol con el nodo ra칤z, llamado S, que contiene el conjunto de datos completo.

**Paso 2**: Encontrar el mejor atributo en el conjunto de datos usando la medida de selecci칩n de atributos (ASM).

**Paso 3**: Dividir el nod S en subconjuntos que contienen valores posibles para los mejores atributos.

**Paso 4**: Generar el nodo del 치rbol de decisi칩n, que contiene el mejor atributo.

**Paso 5**: Hacer 치rboles de decisi칩n nuevos de manera recursiva usando los subconjuntos del conjunto de datos creados en el paso 3. 
Continuar este proceso hasta que se alcance una etapa en la que no pueda clasificar m치s los nodos y llame al nodo final como un nodo hoja.


```{r echo = FALSE, results = 'asis'}
image = "https://static.javatpoint.com/tutorial/machine-learning/images/decision-tree-classification-algorithm.png"
cat(paste0('<center><img src="', image,  '"></center>')) 
```

Fuente : <https://www.javatpoint.com/machine-learning-decision-tree-classification-algorithm> 

## Random Forest

Es un modelo de aprendizaje supervisado el cual nos sirve para regresi칩n o clasificaci칩n, este se encuentra basado en el aprendizaje por ensamble, el cual es un proceso de combinar multiples clasificadores para un mejor resultado.

Como el nombre lo dice el modelo de `Random Forest` es un clasificador el cual contiene multiples 치rboles de decisi칩n con una parte del dataset a entrenas para poder generar un promedio que mejore la precisi칩n de la predici칩n. Es importante que entre m치s n칰mero de 치rboles es mejor para el algoritmo en precisi칩n y en evitar el sobreajuste.

El m칩delo de Random Forest funciona de la siguiente manera:

**Paso 1**: Seleccionamos k registos de nuestros datos

**Paso 2**: Construimos el 치rbol de decisi칩n asociado al subsed de datos.

**Paso 3**: Seleccionamos el n칰mero N de 치rboles de decisi칩n que se piensan construir.

**Paso 4**: Repetimos el paso 1 y el paso 2.

```{r echo = FALSE, results = 'asis'}
image = "https://static.javatpoint.com/tutorial/machine-learning/images/random-forest-algorithm.png"
cat(paste0('<center><img src="', image,  '"></center>')) 
```

Fuente : <https://www.javatpoint.com/machine-learning-random-forest-algorithm> 

# Fase 1-2-3: muestreo-exploraci칩n-modificaci칩n

Ahora examinaremos los datos con el objetivo de poder tomar **decisiones que deber칤amos adoptar**. Por ejemplo:

&nbsp;

* 쯅ecesitamos **muestreo**? 쮻e qu칠 forma? 쯇odremos permitirnos crear un dataset de **validaci칩n**?

* 쮻e qu칠 **tipo** es cada variable? 쯊enemos **problemas de codificaci칩n o rango**?

* 쮺칩mo **afectan las predictoras** a los niveles de la variable objetivo?

* 쮿ay problemas de **dependencia** entre las variables?

* 쯅ecesitamos **recategorizar** las variables? 

* 쯊enemos **datos at칤picos**?  쯊enemos **datos ausentes**? 쮺칩mo imputarlos?

* 쯅ecesitaremos hacer **One Hot Encoding** a nuestras variables categ칩ricas?

&nbsp;

La **filosof칤a** ser치 la siguiente: 

* modificaciones 춺estructurales췉 las hacemos fuera de la receta (modificando la base de datos)

* modificaciones m치s concretas para un algoritmo dentro de la receta (sin modificar la base de datos).

## Factores

Una de las primeras decisiones ser치 dotar a las variables de su **tipolog칤a correcta**: debemos decidir si las variables de tipo texto son **variables cualitativas** (factores) o meros id's.

```{r}
adultos |>
  select(where(is.character)) |>
  glimpse()
```


Todas las variables de tipo texto representan **categor칤as de una cualitativa** as칤 que las convertimos todas ellas a factor (modificaci칩n estructural --> fuera de la receta)

```{r}

adultos <- 
  adultos |>
  mutate(across(where(is.character),  ~str_replace_all(., ",", "")), across(where(is.character), as_factor))
adultos |> select(where(is.factor))
```

### Ordinales

Podemos ver que de todas nuestras variables la educaci칩n puede tener un orden en sus variables.

Primero veamos su distribuci칩n:

```{r}
adultos |>
  count(education) |> 
  mutate(porc = 100*n/sum(n))
```

Vemos que son 16 niveles de variable que reduciremos a 5 niveles.

Pero primero les quitaremos la coma al final


```{r}

adultos <- adultos |> 
 mutate(
    education_transformed = as.factor(case_when(
      education == "Doctorate"  ~ as.character("Grado 5"),
      education == "Prof-school" | education == "Masters"  ~ as.character("Grado 4"),
      education == "Some-college" | education == "Bachelors"  ~ as.character("Grado 3"),
      education == "Assoc-acdm" | education == "Assoc-voc"  ~ as.character("Grado 2"),
      TRUE ~ as.character("Grado 1")
    )))

knitr::kable(adultos |> select(education, education_transformed) |>  unique())
```


Tras ello convertiremos `education_transformed` a cualitativa pero ordinal.

```{r}
adultos <-
  adultos |>
  mutate(education_transformed = factor(education_transformed, levels = c("Grado 1", "Grado 2", "Grado 3", "Grado 4", "Grado 5"),
                       ordered = TRUE))
knitr::kable(adultos |> select(education_transformed) |> arrange(desc(education_transformed)) |> unique() )
```


## Variables cuali

Una vez convertidas en cualitativas analicemos cada una de ellas. La idea b치sica es la siguiente: ver que peso suponen cada nivel en las variables, y adem치s, ver como **afectan los niveles a la variable objetivo**.

### Variable workclass

Ahora procederemos a ver c칩mo se distribuye la variable **clase de trabajo**:

```{r}
adultos |>
  count(workclass, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))


adultos  |> group_by(workclass) |>  
  count(over_50k) |> 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc), nSum = sum(n)) |>  arrange(-nSum, -n) |> 
  select(-nSum) |> ungroup() 

```

Podemos apreciar que existen ciertas agrupaciones que hacen sentido como  `Self-emp-inc` y `Self-emp-not-inc` en un nuevo grupo llamado `Self-Emp` , as칤 como `Local-Gov` y `State-Gov` en `Other-Gov`. Tambi칠n renombraremos el tipo **?** a `Desconocido`.

```{r}

adultos <- adultos |> 
 mutate(
    workclass_transformed = as.factor(case_when(
      workclass == "?"  ~ as.character("Desconocido"),
      workclass == "Local-gov" | workclass == "State-gov"  ~ as.character("Other-Gov"),
      workclass == "Self-emp-inc" | workclass == "Self-emp-not-inc"  ~ as.character("Self-Emp"),
      TRUE ~ as.character(workclass)
    )))

knitr::kable(adultos |> select(workclass, workclass_transformed) |>  unique())
```

### Variable Estado Civil

Ahora procederemos a ver c칩mo se distribuye la variable **Estado Civil**:

```{r}
adultos |>
  count(marital_status, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))


adultos  |> group_by(marital_status) |>  
  count(over_50k) |> 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc), nSum = sum(n)) |>  arrange(-nSum, -n) |> 
  select(-nSum) |> ungroup() 

```

Podemos apreciar que existen ciertas agrupaciones que hacen sentido como  `Married-civ-spouse` y `Married-AF-spouse` en un nuevo grupo llamado `Married` , as칤 como `Divorced`, `Separated`, `Widowed` y `Married-spouse-absent` en `Complicated`.

```{r}

adultos <- adultos |> 
 mutate(
    marital_status_transformed = as.factor(case_when(
      marital_status == "Married-civ-spouse" | marital_status == "Married-AF-spouse"  ~ as.character("Married"),
      marital_status == "Never-married"  ~ as.character("Never-married"),
      TRUE ~ as.character("Complicated")
    )))

knitr::kable(adultos |> select(marital_status, marital_status_transformed) |>  unique())
```



### Variable Ocupaci칩n

Ahora procederemos a ver c칩mo se distribuye la variable **Ocupaci칩n**:

```{r}
adultos |>
  count(occupation, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))


adultos  |> group_by(occupation) |>  
  count(over_50k) |> 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc), nSum = sum(n)) |>  arrange(-nSum, -n) |> 
  select(-nSum) |> ungroup() 

```

Podemos apreciar que existen ciertas agrupaciones que hacen sentido como  `Prof-specialty` y `Exec-managerial` en un nuevo grupo llamado `High-Income` , as칤 como `Protective-serv`, `Tech-support` y `Sales` en `Medium-Income` y el resto en `Low-Income`.

```{r}

adultos <- adultos |> 
 mutate(
    occupation_transformed = as.factor(case_when(
      occupation == "Prof-specialty" | occupation == "Exec-managerial"  ~ as.character("High-Income"),
      occupation == "Protective-serv" | occupation == "Tech-support" | occupation == "Sales"   ~ as.character("Medium-Income"),
      TRUE ~ as.character("Low-Income")
    )))

knitr::kable(adultos |> select(occupation, occupation_transformed) |>  unique())
```

### Variable Relaci칩n

Ahora procederemos a ver c칩mo se distribuye la variable **Relaci칩n**:

```{r}
adultos |>
  count(relationship, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))


adultos  |> group_by(relationship) |>  
  count(over_50k) |> 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc), nSum = sum(n)) |>  arrange(-nSum, -n) |> 
  select(-nSum) |> ungroup() 

```

Podemos apreciar que existen ciertas agrupaciones que pueden hacer sentido como  `Wife` y `Husband` en un nuevo grupo llamado `Boss` , as칤 como el resto en un grupo llamado `Otros`. Esto lo haremos directamente en la receta para dejar al algorimto KNN con esta transformaci칩n y el resto de los algoritmos sin esta transformaci칩n.


### Variable Raza

Ahora procederemos a ver c칩mo se distribuye la variable **Raza**:

```{r}
adultos |>
  count(race, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))


adultos  |> group_by(race) |>  
  count(over_50k) |> 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc), nSum = sum(n)) |>  arrange(-nSum, -n) |> 
  select(-nSum) |> ungroup() 

```
En este caso solo hace sentido agrupar `Amer-Indian-Eskimo` y `Other` en el grupo `Others`, las variables ya que son pocas y concisas, esto lo haremos directamente en la receta.


### Variable Sexo

Ahora procederemos a ver c칩mo se distribuye la variable **Sexo**:

```{r}
adultos |>
  count(sex, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))


adultos  |> group_by(sex) |>  
  count(over_50k) |> 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc), nSum = sum(n)) |>  arrange(-nSum, -n) |> 
  select(-nSum) |> ungroup() 

```
En este caso no hace sentido agrupar ya que son dos categor칤as muy presentes.

### Variable Pa칤s

Ahora procederemos a ver c칩mo se distribuye la variable **Pa칤s**:

```{r}
adultos |>
  count(native_country, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))


adultos  |> group_by(native_country) |>  
  count(over_50k) |> 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc), nSum = sum(n)) |>  arrange(-nSum, -n) |> 
  select(-nSum) |> ungroup() 

```
En este caso solo hace sentido dejar `United States` en un grupo, `Mexico` en otro grupo, `Philippines`,`Germany`,`Canada`,`India`,`England`,`South`,`Italy`,`Japan` y `Taiwan` en el grupo `High Income`, y el resto en el grupo `Others`.

```{r}

adultos <- adultos |> 
 mutate(
    country_transformed = as.factor(case_when(
      native_country %in% c("Philippines","Germany","Canada","India","England","South","Italy","Japan","Taiwan")  ~ "High-Income",
      native_country == "United-States"   ~ as.character(native_country),
      native_country == "Mexico"   ~ as.character(native_country),
      TRUE ~ as.character("Others")
    )))

knitr::kable(adultos |> select(native_country, country_transformed) |>  unique())
```


## Dependencia entre  cuali

Podemos ejecutar un **contraste de independencia** (prueba $\chi^2$ de independencia) para tener mayor certeza de si la predictora es dependiente o no de la variable objetivo (si fuera independiente, no tendr칤a sentido mantenerla)

Podemos hacerlo con **todas las variables a la vez** enfrent치ndola a la objetivo, entendiendo que cada columna juega el rol de una lista si usamos las funciones del paquete `{purrr}`

```{r warning = FALSE}
chisq <-
  tibble("variable" = adultos |> select(where(is.factor)) |> names(),
         "p_value" = adultos |> select(where(is.factor)) |>
           map_dbl(.f = function(x) { chisq.test(adultos$over_50k, x)$p.value}))
chisq |> arrange(desc(p_value))
```


```{r warning = FALSE}
chisq |> filter(p_value > 0.05)
```

**No hay evidencia suficiente para decir que existe predictora independiente de la objetivo** (al 95% de confianza) seg칰n la prueba de independencia realizada


## Variables num칠ricas

Para las num칠ricas el proceso ser치 ligeramente diferente, ya que ya no toman modalidades, aunque la mayor칤a de ellas como veremos podr칤an funcionar tanto de cuanti como de cuali (recategorizadas)

### Horas de Trabajo a la Semana

* `hours_per_week`: en realidad es una variable cualitativa m치s que cuantitativa, y a partir de 2 noches en festivo representa menos de 1% --> podr칤amos probar a **dejarla tal cual o recategorizarla en 4 categor칤as** (ninguna - 1 - 2 - m치s de 2)

```{r}
adultos |>
  count(hours_per_week, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```

```{r}

adultos <- adultos |> 
 mutate(
    hours_per_week_transformed = as.factor(case_when(
      hours_per_week<40 ~ as.character("Menos de 40 Horas"),
      hours_per_week>40 ~ as.character("M치s de 40 horas"),
      TRUE ~ as.character("40 Horas")
    )))

```

Ahora le daremos un orden a las nuevas categor칤as:

```{r}
adultos <-
  adultos |>
  mutate(hours_per_week_transformed = factor(hours_per_week_transformed, levels = c("Menos de 40 Horas", "40 Horas", "M치s de 40 horas"),
                       ordered = TRUE))
knitr::kable(adultos |> select(hours_per_week_transformed) |> arrange(desc(hours_per_week_transformed)) |> unique() )
```

Y as칤 se ver칤a:

```{r}
adultos|> group_by(hours_per_week_transformed) |>  
  count(over_50k) |> 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc), nSum = sum(n)) |>  arrange(-nSum, -n) |> 
  select(-nSum) |> ungroup() 
```

## Colinealidad

Por 칰ltimo, nos falta comprobar los **problemas de  colinealidad** entre las predictoras num칠ricas. Podemos tratar las **num칠ricas por separado** (aunque tengamos muchas que en realidad hacen m치s de cuali que de cuanti)


```{r}
cor_matrix <- adultos |> select(where(is.numeric)) |> cor() |> round(2)

cor_matrix |>
  corrplot( method = 'ellipse', order = 'AOE', type = 'upper')
```


No parece existir una correlaci칩n elevada entre ninguna.


## Fase 3: modificaci칩n (fuera de la receta)

### Sampling

Con lo observado en la fase de exploraci칩n procederemos a hacer un **muestreo estratificado**  del 15% ya que tenemos muchas filas (al menos para hacer pruebas).


```{r}
# Muestreo del 25%
adultos_sample <-
  adultos |>
  group_by(over_50k) |> 
  slice_sample(prop = 0.15) |>
  ungroup()
```


## Fase 3: modificaci칩n (dentro de la receta)

### Partici칩n

#### Test vs lo dem치s

Antes de nada deberemos realizar nuestras particiones, y primero dividiremos en **test y lo dem치s**, con `initial_split()`, teniendo 25% en test y 75% en todo lo dem치s

```{r}
# Partici칩n 10% de test 
adultos_split <- initial_split(adultos_sample, strata = over_50k, prop = 0.75)
adultos_split
```

F칤jate que en `adultos_split` solo tenemos las instrucciones. Vamos a aplicarlas

```{r}
# Aplicamos partici칩n
train_data <- training(adultos_split)
test_data <- testing(adultos_split)
```

Tras ello nunca est치 de m치s comprobar que efectivamente lo ha realizado de manera estratificada

```{r}
# Comprobamos estratos
train_data |> count(over_50k) |> mutate(porc = 100 * n / sum(n))
test_data |> count(over_50k) |> mutate(porc = 100 * n / sum(n))
```


#### Validaci칩n

Dado que no siempre disponemos de un volumen suficiente de datos, una **opci칩n muy com칰n y que arroja unos resultados bastante buenos** es la llamada **validaci칩n cruzada v-folds**: dividimos en $v$ trozos nuestro conjunto de entrenamiento, de forma que realizamos las siguientes iteraciones:

* Iteraci칩n 1: entrenamos el modelo con los conjuntos $\left\lbrace 2, 3, \ldots, v \right\rbrace$ y validamos con el primer conjunto.

* Iteraci칩n 2: entrenamos el modelo con los conjuntos $\left\lbrace 1, 3, \ldots, v \right\rbrace$ y validamos con el segundo conjunto.

...

* Iteraci칩n v: entrenamos el modelo con los conjuntos $\left\lbrace 1, 2, \ldots, v1 \right\rbrace$ y validamos con el conjunto $v$-칠simo.

Este m칠todo nos permite, no solo no tener que disponer de un alto volumen de datos sino que adem치s **la validaci칩n ya no es sobre una sola muestra sino un promedio de varias** (eso s칤, muestras relacionadas entre s칤, no son independientes). Adem치s con `strata` le diremos que dichas particiones las hagan estratificadas para conservar 0's-1's.


```{r}
# Fijamos la semilla
set.seed(100)

# Declaramos el n칰mero de particiones en las que procederemos a validar.
cv_folds <-
 vfold_cv(train_data, 
          v = 5, 
          strata = over_50k,
          repeats = 1) 
```

### Roles

Tras las particiones, el primer paso es **definir la receta**, indic치ndole el conjunto donde tenemos validaci칩n y train, y enfrentar `over_50k` con todas. Despu칠s lo que haremos ser치 **asignar posibles roles** que nos puedan diferencias las acciones entre las variables


```{r}
# Receta
rec_adultos <-
  # F칩rmula y datos
  recipe(data = train_data, over_50k ~ .)|>
  # Roles
  add_role(where(is.factor), new_role = "cuali") |> 
  add_role(where(is.numeric), new_role = "cuanti") |> 
  add_role(c(workclass, marital_status, occupation, native_country, hours_per_week, education, education_num), new_role = "Drop_Columns")
```


###Receta KNN

Ahora procederemos en crear la receta par el algoritmo KNN

```{r}
# Receta
KNN_rec_adultos <-
  rec_adultos  |> 
  # Modificaci칩n de variables actuales
  step_mutate(
    relationship =
                as.factor(case_when(
      relationship %in% c("Wife","Husband")  ~ "Boss",
      TRUE ~ "Others")),
    race =
                as.factor(case_when(
      race %in% c("Amer-Indian-Eskimo","Other")  ~ "Others",
      TRUE ~ as.character(race)))) |>
  # Eliminamos variables predefinidas.
  step_rm(has_role("Drop_Columns"))|> 
  # Detectar outliers
  step_mutate(across(where(is.numeric), function(x) { ifelse(abs(scores(x,type = "iqr")) > 1.5 & !is.na(x), NA, x) })) |> 
  # Imputamos ausentes (podr칤amos dejarlas como una categor칤a m치s)
  step_impute_knn(has_role("cuanti")) |> 
  step_impute_mode(has_role("cuali")) |> 
  # Remover nulos
  step_naomit(everything(), skip = TRUE) |> 
  # Agrupamos en Minority los valores menos a 5%
  step_other(has_role("cuali"), threshold = .05, other = "Minority")  |> 
  # Escalamos los valores
  step_range(has_role("cuanti")) |> 
  # Normalizamos
  step_normalize(has_role("cuanti")) |> 
  # Dummyficamos
  step_dummy(all_nominal(), -all_outcomes())  |> 
  step_zv(all_predictors()) |> 
  step_corr(has_role("cuanti"), threshold = 0.7)  #|> 
```

Probaremos la receta para ver sus resultados:

```{r}
prepped_data <- 
  KNN_rec_adultos |>  # use the recipe object
  prep() |>  # perform the recipe on training data
  juice() # extract only the preprocessed dataframe 

glimpse(prepped_data)
```

### Receta CART

Ahora procederemos con la receta para crear el modelo de 치rboles de decisi칩n.

```{r}
# Receta
cart_rec_adultos <-
  rec_adultos  |> 
  # Removeremos variables
  step_rm(has_role("Drop_Columns"))|> 
  # Detectaremos outliers con base al "z"test.
  step_mutate(across(where(is.numeric), function(x) { ifelse(abs(scores(x,type = "z")) >2.5 & !is.na(x), NA, x) })) |> 
  # Imputamos ausentes
  step_impute_median(has_role("cuanti")) |> 
  step_impute_mode(has_role("cuali")) |> 
  # Removemos valores nulos
  step_naomit(everything(), skip = TRUE) |> 
  # Agrupamos en Minority los valores menos a 5%
  step_other(has_role("cuali"), threshold = .05, other = "Minority")  |> 
  # Eliminamos variables con varianza 0
  step_zv(all_predictors()) |> 
  # Eliminamos variables con correlaci칩n mayor al 70%
  step_corr(has_role("cuanti"), threshold = 0.7)  |> 
  # Sobremuestreo 66% - 33%
  themis::step_upsample(over_50k, over_ratio = 0.5) 
```

Probamos la receta:

```{r}
cart_prepped_data <- 
  cart_rec_adultos |>  # use the recipe object
  prep() |>  # perform the recipe on training data
  juice() # extract only the preprocessed dataframe 

glimpse(cart_prepped_data)
```

### Receta Random Forest

Ahora procederemos a crear la receta para la modelaci칩n con el algoritmo Random Forest:

```{r}
# Receta
rf_rec_adultos <-
  rec_adultos  |> 
  # Agru
  step_rm(has_role("Drop_Columns"))|> 
  # Detectar outliers
  step_mutate(across(where(is.numeric), function(x) { ifelse(abs(scores(x,type = "z")) >2.5 & !is.na(x), NA, x) })) |> 
  # Imputamos ausentes (podr칤amos dejarlas como una categor칤a m치s)
  step_impute_knn(has_role("cuanti")) |> 
  step_impute_mode(has_role("cuali")) |> 
  # Removemos nulos
  step_naomit(everything(), skip = TRUE) |>
  # Agrupamos con Tag Minority a los grupos de valores en las variables que representen menos del 4%
  step_other(has_role("cuali"), threshold = .04, other = "Minority")  |> 
  # Reagrupamos
  step_zv(all_predictors()) |> 
  step_corr(has_role("cuanti"), threshold = 0.7)  |> 
  # Sobremuestreo 50-50%
  themis::step_upsample(over_50k, over_ratio = 1) 
```


Probamos la receta para el algoritmo de Random Forest:

```{r}
rf_prepped_data <- 
  rf_rec_adultos |>  # use the recipe object
  prep() |>  # perform the recipe on training data
  juice() # extract only the preprocessed dataframe 

glimpse(rf_prepped_data)
```

# Fase 4 Modelling

## Metodolog칤a

Primero evaluaremos cada uno de los modelos por separado (KNN, CART, Random Forest) utilizando slice_sample seleccionaremos aleatoriamente 10 diferentes combinaciones de par치metros y con procesamiento en paralelo seleccionaremos el que tenga mejores resultados de cada uno de ellos. Al terminar la selecci칩n del mejor modelo, los compararemos entre ellos y seleccionaremos al mejor para hacer un Grid Search completo con validaci칩n cruzada y doble repetici칩n para encontrar el mejor resultado posible.


## C칩mputo en Paralelo

Vamos a **paralelizar en NUESTRO PROPIO ORDENADOR**: un ordenador suele tener **varios procesadores o cores** que pueden funcionar de manera 춺independiente췉 uno de otro. Vamos a detectar la cantidad de n칰cleos de los que podemos disponer con `detectCores()`.

```{r}
# Detectamos los cores que tenemos
detectCores()
```

A la hora de paralelizar es importante que lo hagamos con cuidado ya que puede que nuestro ordenador se quede colgado: mi consejo es que definas el n칰mero de cores a usar como los que tienes menos uno.

Con `makeCluster()` montamos los **cl칰ster en cada nodo** y con `registerDoParallel()` registramos la paralelizaci칩n (puedes ver los hilos abiertos con `showConnections()`).

```{r}
# Iniciamos la paralelizaci칩n
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)
showConnections()
```

## Fase 4 KNN: modelo y flujo

### Flujo Modelo KNN

Empezamos a realizar el modelo KNN

```{r}
# Modelo
knn_model <-
  nearest_neighbor(mode = "classification", neighbors = tune("k"),
                   weight_func = tune("weight"), dist_power = tune("dist")) |>
  set_engine("kknn")

# Flujo de trabajo
knn_wflow_adultos <-
  workflow() |>
  add_recipe(KNN_rec_adultos) |>
  add_model(knn_model)
```

### Grid KNN

Ahora formaremos el grid para el modelo KNN

```{r}
grid_knn <-
  extract_parameter_set_dials(knn_wflow_adultos) |>
  # Actualizamos
  update(k = neighbors(range = c(90, 110)),
         weight = weight_func(values = c("inv","gaussian")),
         dist = dist_power(range = c(4, 6))) |>
  grid_regular(levels = 3) 
grid_knn <- grid_knn |> slice_sample(n=10) # 18 modelos (3 x 2 x 3)
grid_knn
```
### Aplicaci칩n del flujo de trabajo

```{r}
# Aplicamos el flujo
knn_fit_tune <- 
  knn_wflow_adultos |> 
  tune_grid(
    resamples = cv_folds, 
    metrics = metric_set(recall, precision, accuracy,roc_auc, sens, f_meas),
    grid = grid_knn,
    control = control_grid(verbose = TRUE, allow_par = TRUE, #<<
                                   pkgs = c("outliers")),
 ) 

# Best Model
knn_fit_tune |> show_best("roc_auc")

# Finalizamos flujo con el mejor modelo (seg칰n una m칠trica)
best_knn_model_auc <- knn_fit_tune |> select_best("roc_auc")

```

### Selecci칩n de Mejor Modelo

```{r}
final_knn_wf <- 
  knn_wflow_adultos |> 
  finalize_workflow(best_knn_model_auc)


final_knn_fit <- 
  final_knn_wf |>
  last_fit(adultos_split, 
           metrics = metric_set(recall, precision, accuracy,roc_auc, sens, f_meas)) 

# Recolectamos las m칠tricas de error
final_knn_fit |> collect_metrics(summarize = TRUE)

```

### Matriz de Confusi칩n

Ahora es importante saber c칩mo se visualiza la matriz de confusi칩n

```{r}

knn_pred <- 
  final_knn_fit |>
  collect_predictions() 


knn_pred |> 
  conf_mat(over_50k, .pred_class) |> 
  autoplot(type = "heatmap") 
```

### Curva ROC 

Hacemos la curva ROC para medir la calidad de la predicci칩n

```{r}

knn_pred |> 
  group_by(id) |>
  roc_curve(over_50k, `.pred_<=50K`) |> 
  autoplot() +
  theme_economist_white()
```


### Probability Distribution Plot

Veamos la densidad de nuestra predicci칩n.

```{r}

knn_pred |> 
  ggplot() +
  geom_density(aes(x = `.pred_<=50K`, 
                   fill = over_50k), 
               alpha = 0.5) +
  theme_economist()
```

Podemos ver c칩mo nuestro modelo se comporta totalmente diferente al poder definir las personas con un ingreso mayor a 50 K las cuales se encuentran en su mayor칤a a partir del 77% de probabilidad de pertenencia.

## Fase 4 CART: modelo y flujo

### Flujo Modelo CART

Empezamos a realizar el modelo CART

```{r}
# Modelo
cart_model <- decision_tree <-
  decision_tree(mode = "classification",
                tree_depth = tune("depth"),
                min_n = tune("min_split"),
                cost_complexity = tune("cost")) |> 
  set_engine("rpart")

# Flujo de trabajo
cart_wflow_adultos <-
  workflow() |>
  add_recipe(cart_rec_adultos) |>
  add_model(cart_model)

# Par치metros a optimizar
param <- parameters(cart_model)
param$object

```

### Grid CART

```{r}

# Construimos el grid de par치metros
grid_tree <-
  parameters(cart_wflow_adultos) |>
  # Actualizamos
  update(depth = tree_depth(range = c(3, 8)),
         min_split = min_n(range = round(c(0.01, 0.1) * nrow(test_data),0)),
         cost = cost_complexity(range = c(-5, -1),
                                trans = log10_trans())) |>
  grid_regular(levels = 3) 
grid_tree_sample <- grid_tree |> slice_sample(n=10) # 10 modelos

grid_tree_sample
```


###  Aplicaci칩n del flujo de trabajo

```{r}
#Ejecuci칩n del flujo de trabajo
cart_fit_tune <- 
  cart_wflow_adultos |> 
  tune_grid(
    resamples = cv_folds, 
    metrics = metric_set(recall, precision, accuracy,roc_auc, sens, f_meas),
    grid = grid_tree_sample,
    control = control_grid(verbose = TRUE, allow_par = TRUE, #<<
                                   pkgs = c("outliers")),
 ) 

# Best Model
cart_fit_tune |> show_best("roc_auc")

# Finalizamos flujo con el mejor modelo (seg칰n una m칠trica)
best_cart_model_auc <- cart_fit_tune |> select_best("roc_auc")

```


### Selecci칩n del mejor modelo

```{r}
final_cart_wf <- 
  cart_wflow_adultos |> 
  finalize_workflow(best_cart_model_auc)


final_cart_fit <- 
  final_cart_wf |>
  last_fit(adultos_split, 
           metrics = metric_set(recall, precision, accuracy,roc_auc, sens, f_meas)) 

# Recolectamos las m칠tricas de error
final_cart_fit |> collect_metrics(summarize = TRUE)

```

### Matriz de Confusi칩n
```{r}

cart_pred <- 
  final_cart_fit |>
  collect_predictions()


cart_pred |> 
  conf_mat(over_50k, .pred_class) |> 
  autoplot(type = "heatmap") 
```

Podemos ver que este modelo presenta mejores resultados que el KNN.

### Curva ROC
```{r}
# Matriz de confusi칩n: etiqueta real vs etiqueta predicha
cart_pred |> 
  group_by(id) |> # id contains our folds
  roc_curve(over_50k, `.pred_<=50K`) |> 
  autoplot() +
  theme_economist_white()

```


### Probability Distribution Plot

```{r}
cart_pred |> 
  ggplot() +
  geom_density(aes(x = `.pred_<=50K`, 
                   fill = over_50k), 
               alpha = 0.5) +
  theme_economist()
```


Podemos ver que el modelo de 치rboles de decisi칩n es mejor distribuyendo la diferencia en proporciones al determinar si un individuo percibe o no 50 mil d칩lares anuales, generando m칰ltiples m치ximos locales a trav칠s de su distribuci칩n.

### Visualizar el 치rbol

Tambi칠n podemos visualizar f치cilmente los 치rboles generados con CART (Gini, del paquete `{rpart}`): primero con `extract_fit_engine()` extraemos las rutas del 치rbol, y despu칠s con `rpart.plot(roundint = FALSE, extra = 4)` le indicamos que no redondee valores a enteros y de los modelos de visualizaci칩n elegimos `extra = 4` (prueba con varios para ver las diferencias). Para visualizar 치rboles `C5.0` ver documentaci칩n en <https://topepo.github.io/C5.0/reference/plot.C5.0.html>

```{r visualizar}
final_cart_fit |>
 extract_fit_engine() |>
  rpart.plot(roundint = FALSE, extra = 4)
```

### Importancia de las variables

Veamos las variables m치s importantes del 치rbol de decisi칩n.

```{r}
final_cart_fit |> 
  pluck(".workflow", 1) |>   
  pull_workflow_fit() |> 
  vip(num_features = 10)
```

Vemos que la variable m치s importante es el papel que la persona tiene en su familia y su estado civil, esto puede ser muy l칩gico porque en el a침o que se recolectaron los datos exist칤a cierta inclinaci칩n a ofrecer mejores beneficios a las personas con estabilidad familiar. 

## Fase 4 Random Forest: modelo y flujo

### Flujo Modelo Random Forest

Ahora empecemos con el flujo de trabajo del Random Forest:

```{r}
# Modelo
rf_spec <- 
  rand_forest(mtry = tune("p_mtry"), min_n = tune("p_min"), trees = tune("p_trees"))  |> 
  set_engine("ranger", importance = "impurity") |> 
  set_mode("classification")


# Flujo de trabajo
rf_wflow_adultos <-
 workflow() |>
 add_recipe(rf_rec_adultos) |> 
 add_model(rf_spec) 


# Par치metros a optimizar
param <- parameters(rf_wflow_adultos)
param$object

```

Podemos ver que este modelo cuenta con 3 par치metros a optimizar, los cuales son el n칰mero de arboles, el n칰mero de predictores y el n칰mero de nodos.

### Grid Random Forest


```{r}
# Construimos el grid de par치metros
grid_rf <-
  parameters(rf_wflow_adultos) |>
  # Actualizamos
  update(p_mtry = mtry(range = c(4, 9)),
         p_min = min_n(range = round(c(0.01, 0.1) * nrow(test_data),0)),
         p_trees = trees(range = c(5, 100))) |>
  grid_regular(levels = 4) 


grid_rf_sample <- grid_rf |> slice_sample(n=10) # 10 modelos

grid_rf_sample
```

### Aplicaci칩n del flujo de trabajo

```{r}
# Aplicamos el flujo
rf_fit_tune <- 
  rf_wflow_adultos |> 
  tune_grid(
    resamples = cv_folds, 
    metrics = metric_set(recall, precision, accuracy,roc_auc, sens, f_meas),
    grid = grid_rf_sample,
    control = control_grid(verbose = TRUE, allow_par = TRUE, #<<
                                   pkgs = c("outliers")),
 ) 

# Mejor modelo
rf_fit_tune |> show_best("roc_auc")

# Finalizamos flujo con el mejor modelo (seg칰n una m칠trica)
best_rf_model_auc <- rf_fit_tune |> select_best("roc_auc")

```
### Selecci칩n de Mejor Modelo

```{r}
final_rf_wf <- 
  rf_wflow_adultos |> 
  finalize_workflow(best_rf_model_auc)


final_rf_fit <- 
  final_rf_wf |>
  last_fit(adultos_split, 
           metrics = metric_set(recall, precision, accuracy,roc_auc, sens, f_meas)) 

# Recolectamos las m칠tricas de error
final_rf_fit |> collect_metrics(summarize = TRUE)

```

### Matriz de Confusi칩n

```{r}

rf_pred <- 
  final_rf_fit |>
  collect_predictions()


rf_pred |> 
  conf_mat(over_50k, .pred_class) |> 
  autoplot(type = "heatmap") 
```

Podemos ver que existe una mejora importante entre el modelo de Random Forest y los dos anteriores, prediciendo de mejor manera los 

### Curva ROC


```{r}
# Matriz de confusi칩n: etiqueta real vs etiqueta predicha
rf_pred |> 
  group_by(id) |> # id contains our folds
  roc_curve(over_50k, `.pred_<=50K`) |> 
  autoplot() +
  theme_economist_white()

```


### Probability Distribution Plot

```{r}
rf_pred |> 
  ggplot() +
  geom_density(aes(x = `.pred_<=50K`, 
                   fill = over_50k), 
               alpha = 0.5) +
  theme_economist()
```

El modelo muestra una gran diferencia entre los dos c칰mulos de probabilidades, cada uno inclin치ndose m치s hacia un lado y haciendo m치s certero al modelo.

### Importancia de las variables

```{r}
final_rf_fit |> 
  pluck(".workflow", 1) |>   
  pull_workflow_fit() |> 
  vip(num_features = 10)
```

Podemos ver que sigue siendo las dos variables m치s importantes el estado civil y la relaci칩n familiar para determinar el ingreso del individuo.

## Comparaci칩n de Modelos

Procederemos a comparar los 3 modelos que anteriormente hemos hecho.

```{r}
# Resultados Random Forest
rf_metrics <- 
  final_rf_fit |> 
  collect_metrics(summarise = TRUE) |>
  mutate(model = "Random Forest")

# Resultados Decision Tree
cart_metrics <- 
  final_cart_fit |> 
  collect_metrics(summarise = TRUE) |>
  mutate(model = "CART")

# Resultados KNN
knn_metrics <- 
  final_knn_fit |> 
  collect_metrics(summarise = TRUE) |>
  mutate(model = "KNN")

# Juntando resultados
model_compare <- bind_rows(rf_metrics,
                           cart_metrics,
                           knn_metrics,
                           ) 
# Modelando tabla para resultados
model_comp <- 
  model_compare |> 
  select(model, .metric, .estimate) |> 
  pivot_wider(names_from = .metric, values_from = c(.estimate)) 


# Graficando resultados 
model_comp |> 
  arrange(roc_auc) |> 
  mutate(model = fct_reorder(model, roc_auc)) |> # Ordenando Resultados
  ggplot(aes(model, roc_auc, fill=model)) +
  geom_col() +
  coord_flip() +
  scale_fill_brewer(palette = "Blues") +
   geom_text(
     size = 3,
     aes(label = round(roc_auc, 2), y = roc_auc + 0.08),
     vjust = 1
  )
```

Siendo el modelo con mejor ROC_AUC el siguiente:

```{r}
model_comp |> slice_max(n=1, roc_auc)
```
 
### Comparaci칩n Curva ROC

Ahora veamos los resultados en una sola curva ROC.

```{r}
rf_pred_auc <- rf_pred |>  mutate(model= "rf")

cart_pred_auc <- cart_pred |>  mutate(model= "cart")

knn_pred_auc <- knn_pred |>  mutate(model= "knn")

roc_out <- bind_rows(rf_pred_auc, cart_pred_auc,knn_pred_auc)

roc_out %>%
  group_by(model) %>% # Agrupando valores
  roc_curve( truth = over_50k, `.pred_<=50K`) |> # Valores para graficar la curva ROC
  ggplot(
    aes(
      x = 1 - specificity, 
      y = sensitivity, 
      color = model
    )
  ) + # plot with 2 ROC curves for each model
  geom_line(size = 1.1) +
  geom_abline(slope = 1, intercept = 0, size = 0.4) +
  scale_color_manual(values = c("#48466D", "#3D84A8","#D24E01")) +
  coord_fixed() +
  theme_economist_white()
 
```

Podemos ver que el modelo que m치s cubre 치rea en la gr치dica es el Random Forest y el que menos abarca es el modelo KNN
## Fase 4 Hyper Tunning 

### Validaci칩n con repetici칩n

```{r}
# Declaramos el n칰mero de particiones en las que procederemos a validar.
cv_folds <-
 vfold_cv(train_data, 
          v = 5, 
          strata = over_50k,
          repeats = 2) 
```


### Aplicaci칩n de flujo de trabajo

Con base a los resultados podemos concluir que el modelo m치s adecuado es el **Random Forest** con los siguientes par치metros:

```{r}
# Best Model
rf_fit_tune |> show_best("roc_auc") |> slice_max(mean, n=1)

```

Con esto podemos optimizar el grid para encontrar el mejor modelo posible:

```{r}

# Construimos el grid de par치metros
grid_final_rf <-
  parameters(rf_wflow_adultos) |>
  # Actualizamos
  update(p_mtry = mtry(range = c(4, 6)),
         p_min = min_n(range = round(c(0.5, 0.15) * nrow(test_data),0)),
         p_trees = trees(range = c(20, 60))) |>
  grid_regular(levels = 3) 


grid_final_rf
```

Y aplicarlo al flujo de trabajo.

```{r}
# Aplicamos el flujo
rf_final_fit_tune <- 
  rf_wflow_adultos |> 
  tune_grid(
    resamples = cv_folds, 
    metrics = metric_set(recall, precision, accuracy,roc_auc, sens, f_meas),
    grid = grid_final_rf,
    control = control_grid(verbose = TRUE, allow_par = TRUE, #<<
                                   pkgs = c("outliers")),
 ) 

# Mejor Modelo
rf_final_fit_tune |> show_best("roc_auc")

# Finalizamos flujo con el mejor modelo (seg칰n una m칠trica)
best_rf_final_model_auc <- rf_final_fit_tune |> select_best("roc_auc")

```

Y finalizamos el c칩mputo en paralelo. (ya no ser치 necesario)

```{r}
# finalizamos clusters
stopCluster(make_cluster)
registerDoSEQ()
```


### Selecci칩n de Mejor Modelo

Entrenaremos el modelo final con los par치metros del mejor modelo.

```{r}

final_rf_wf <- 
  rf_wflow_adultos |> 
  finalize_workflow(best_rf_final_model_auc)

final_rf_fit <- 
  final_rf_wf |>
  last_fit(adultos_split, 
           metrics = metric_set(recall, precision, accuracy,roc_auc, sens, f_meas)) 

final_rf_fit |> collect_metrics(summarize = TRUE)

```

### Matriz de Confusi칩n

Visualizemos la matriz de confusi칩n del modelo final

```{r}

rf_final_pred <- 
  final_rf_fit |>
  collect_predictions()


rf_final_pred |> 
  conf_mat(over_50k, .pred_class) |> 
  autoplot(type = "heatmap") 
```
Podemos ver que tiene un mejor performance que el modelo pasado, con una ligera mejora en el cuadrante verdadero positivo.


### Probability Distribution Plot

```{r}
rf_final_pred |> 
  ggplot() +
  geom_density(aes(x = `.pred_<=50K`, 
                   fill = over_50k), 
               alpha = 0.5) +
  theme_economist()
```
Podemos ver que el resultado es muy similiar al pasado Random Forest.

### Comparaci칩n entre modelos

Veamos una comparaci칩n entre los modelos construidos.

```{r}
rf_final_metrics <- 
  final_rf_fit |> 
  collect_metrics(summarise = TRUE) |>
  mutate(model = "Random Forest Final")

model_compare_vf <- bind_rows(model_compare,rf_final_metrics) 

model_comp <- 
  model_compare_vf |> 
  select(model, .metric, .estimate) |> 
  pivot_wider(names_from = .metric, values_from = c(.estimate)) 

 
model_comp |> 
  arrange(roc_auc) |> 
  mutate(model = fct_reorder(model, roc_auc)) |> # order results
  ggplot(aes(model, roc_auc, fill=model)) +
  geom_col() +
  coord_flip() +
  scale_fill_brewer(palette = "Blues") +
   geom_text(
     size = 3,
     aes(label = round(roc_auc, 2), y = roc_auc + 0.08),
     vjust = 1
  )
```
El modelo final tiene un AUC score un poco m치s alto que el pasado Random Forest.

### Curva ROC entre modelos

Ahora visualizemos la curva ROC de nuestros 4 modelos.

```{r}
rf_final_pred_auc <- rf_final_pred |>  mutate(model= "rf final")


roc_out_final <- bind_rows(rf_final_pred_auc, roc_out)

roc_out_final %>%
  group_by(model) %>% # group to get individual ROC curve for each model
  roc_curve( truth = over_50k, `.pred_<=50K`) |> # get values to plot an ROC curve
  ggplot(
    aes(
      x = 1 - specificity, 
      y = sensitivity, 
      color = model
    )
  ) + # plot with 2 ROC curves for each model
  geom_line(size = 1.1) +
  geom_abline(slope = 1, intercept = 0, size = 0.4) +
  scale_color_manual(values = c("#E69F00", "#56B4E9", "#009E73", "#F0E442")) +
  coord_fixed() +
  theme_economist_white()
 
```
